{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Explicação do código\n",
        "Este código foi desenvolvido para processar dois conjuntos de dados: um contendo dados de pesquisas e outro com dados sobre instituições de ensino superior (IES) no Brasil. O objetivo é limpar e selecionar informações relevantes de ambos os conjuntos de dados e, em seguida, combiná-los com base no estado (UF).\n",
        "\n",
        "Vamos dividir o código seção por seção:"
      ],
      "metadata": {
        "id": "Mmm5-oXJef3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta seção importa duas bibliotecas Python necessárias:\n",
        "\n",
        "`pandas:` Esta é uma biblioteca fundamental para manipulação e análise de dados, fornecendo estruturas de dados como DataFrames. É comumente usada para ler, limpar, transformar e analisar dados tabulares.\n",
        "\n",
        "`re:` Este é o módulo integrado do Python para expressões regulares, que são usadas para correspondência de padrões em strings. Neste código, ele será usado para limpar nomes de colunas.\n",
        "# Parte 1: Limpeza e seleção da pesquisa \"State of Datda\""
      ],
      "metadata": {
        "id": "_mfN8D-zemFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8yrdw1A7ema7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Parte 1: Limpeza e Seleção do \"State of Data\" (usando sua lógica) ---\n",
        "\n",
        "print(\"Iniciando Parte 1: Limpeza e seleção do 'State of Data'...\")\n",
        "# Carrega o arquivo CSV. A primeira linha (cabeçalho) contém os nomes das colunas no formato \"('código', 'descrição')\".\n",
        "df_survey = pd.read_csv('State_of_data_BR_2023_Kaggle - df_survey_2023.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAqB8BFAe4h9",
        "outputId": "4317081f-7173-4baa-99ea-2fe91f858bf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando Parte 1: Limpeza e seleção do 'State of Data'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte começa imprimindo uma mensagem indicando o início do processo. Em seguida, carrega um arquivo CSV `'State_of_data_BR_2023_Kaggle - df_survey_2023.csv'`em um DataFrame do Pandas chamado df_survey. Este DataFrame agora contém os dados brutos da pesquisa.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RrJEksZNe87q"
      }
    },
    {
      "source": [
        "# --- Lógica de Seleção de Colunas (Original Mantida) ---\n",
        "fixed_columns = [\n",
        "    \"('P1_a ', 'Idade')\", \"('P1_b ', 'Genero')\", \"('P1_c ', 'Cor/raca/etnia')\",\n",
        "    \"('P1_l ', 'Nivel de Ensino')\", \"('P2_f ', 'Cargo Atual')\", \"('P2_g ', 'Nivel')\",\n",
        "    \"('P2_h ', 'Faixa salarial')\", \"('P2_c ', 'Numero de Funcionarios')\", \"('P2_b ', 'Setor')\",\n",
        "    \"('P2_r ', 'Atualmente qual a sua forma de trabalho?')\", \"('P2_s ', 'Qual a forma de trabalho ideal para você?')\",\n",
        "    \"('P2_i ', 'Quanto tempo de experiência na área de dados você tem?')\",\n",
        "    \"('P2_k ', 'Você está satisfeito na sua empresa atual?')\", \"('P1_i_1 ', 'uf onde mora')\"\n",
        "]\n",
        "\n",
        "p2_l_columns = [col for col in df_survey.columns if col.startswith(\"('P2_l_\")]\n",
        "p2_o_columns = [col for col in df_survey.columns if col.startswith(\"('P2_o_\")]\n",
        "p4_j_columns = [col for col in df_survey.columns if col.startswith(\"('P4_j_\")] # Ferramentas de IA/ML\n",
        "p4_k_columns = [col for col in df_survey.columns if col.startswith(\"('P4_k_\")] # Serviços de Cloud\n",
        "p4_l_columns = [col for col in df_survey.columns if col.startswith(\"('P4_l_\")] # Tecnologias de IA Generativa\n",
        "p3_d_columns = [col for col in df_survey.columns if col.startswith(\"('P3_d_\")] # Habilidades Técnicas\n",
        "p3_e_columns = [col for col in df_survey.columns if col.startswith(\"('P3_e_\")] # Habilidades Comportamentais\n",
        "\n",
        "selected_columns = (fixed_columns + p2_l_columns + p2_o_columns +\n",
        "                    p4_j_columns + p4_k_columns + p4_l_columns +\n",
        "                    p3_d_columns + p3_e_columns)\n",
        "\n",
        "selected_columns = [col for col in selected_columns if col in df_survey.columns]\n",
        "df_selected = df_survey[selected_columns].copy()\n",
        "\n",
        "# --- Limpeza e Tratamento de Nulos (Original Mantido) ---\n",
        "target_col = \"('P2_k ', 'Você está satisfeito na sua empresa atual?')\"\n",
        "df_selected.loc[:, target_col] = df_selected[target_col].astype(str)\n",
        "df_cleaned_survey = df_selected.dropna(subset=[target_col])\n",
        "df_cleaned_survey = df_cleaned_survey[df_cleaned_survey[target_col] != 'Desconhecido']\n",
        "\n",
        "dynamic_prefixes = (\"('P2_l_\", \"('P2_o_\", \"('P4_j_\", \"('P4_k_\", \"('P4_l_\", \"('P3_d_\", \"('P3_e_\")\n",
        "\n",
        "for col in df_cleaned_survey.columns:\n",
        "    if col.startswith(dynamic_prefixes):\n",
        "        df_cleaned_survey.loc[:, col] = df_cleaned_survey[col].fillna(0)\n",
        "    else:\n",
        "        df_cleaned_survey.loc[:, col] = df_cleaned_survey[col].fillna('Desconhecido')\n",
        "\n",
        "print(\"'State of Data' limpo e selecionado com sucesso.\")\n",
        "\n",
        "\n",
        "# --- PRINCIPAL ALTERAÇÃO: Renomeação Inteligente das Colunas ---\n",
        "\n",
        "# --- PRINCIPAL ALTERAÇÃO: Renomeação Inteligente das Colunas ---\n",
        "\n",
        "def get_clean_column_name(col_name):\n",
        "    \"\"\"\n",
        "    Extrai a parte descritiva do nome da coluna e a limpa para ser usada como um identificador.\n",
        "    Exemplo: \"('P4_j_1 ', 'Azure Machine Learning')\" -> \"azure_machine_learning\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Usa regex para encontrar o texto da descrição de forma segura\n",
        "        match = re.search(r\",\\s*'(.*)'\\)\", col_name)\n",
        "        if match:\n",
        "            name = match.group(1).strip()\n",
        "            # Converte para minúsculas e substitui espaços e outros caracteres por underscore\n",
        "            clean_name = re.sub(r'[\\s/,-]+', '_', name.lower())\n",
        "            # Remove underscores duplicados que possam ter sido criados\n",
        "            return re.sub(r'__+', '_', clean_name)\n",
        "    except (IndexError, AttributeError):\n",
        "        # Se a extração falhar, usa o código da coluna como fallback\n",
        "        pass\n",
        "\n",
        "    code_match = re.search(r\"\\('(.+?)',\", col_name)\n",
        "    if code_match:\n",
        "      return code_match.group(1).strip().replace(' ', '') # Limpa o código também\n",
        "\n",
        "    return col_name\n",
        "\n",
        "# Cria o mapa de renomeação usando a função acima para todos os nomes de coluna\n",
        "rename_map = {col: get_clean_column_name(col) for col in df_cleaned_survey.columns}\n",
        "\n",
        "# Renomeia todas as colunas de uma vez\n",
        "df_cleaned_survey.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "print(\"Colunas renomeadas com sucesso usando os nomes exatos.\")\n",
        "\n",
        "# **>>>>>> ADICIONE AS SEGUINTES LINHAS AQUI <<<<<<**\n",
        "print(\"\\nValores únicos na coluna de satisfação após renomeação:\")\n",
        "print(df_cleaned_survey['você_está_satisfeito_na_sua_empresa_atual?'].value_counts(dropna=False))\n",
        "# **>>>>>> FIM DAS LINHAS A SEREM ADICIONADAS <<<<<<**\n",
        "\n",
        "\n",
        "# --- Criação da Coluna 'emprego_status' ---\n",
        "# O nome da coluna 'Cargo Atual' foi alterado para 'cargo_atual' pela função de limpeza.\n",
        "df_cleaned_survey['emprego_status'] = np.where(df_cleaned_survey['cargo_atual'] == '14', 'Desempregado', 'Empregado')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "bX4A0GXufLgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ae5fd1-a507-4d11-ebcf-e86b6de677f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'State of Data' limpo e selecionado com sucesso.\n",
            "Colunas renomeadas com sucesso usando os nomes exatos.\n",
            "\n",
            "Valores únicos na coluna de satisfação após renomeação:\n",
            "você_está_satisfeito_na_sua_empresa_atual?\n",
            "1.0    3420\n",
            "0.0    1333\n",
            "nan     540\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-14f0b9644c4d>:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.0' '1.0' '1.0' ... '1.0' 'nan' 'nan']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df_selected.loc[:, target_col] = df_selected[target_col].astype(str)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, uma lista chamada` fixed_columnsé `criada. Essa lista contém os nomes de colunas específicas do conjunto de dados da pesquisa que são consideradas essenciais para a análise. Os nomes dessas colunas parecem estar em um formato que inclui um código e uma descrição. O comentário indica que a `'P1_i_1 `'coluna (que representa o estado onde a pessoa reside) é crucial para a posterior combinação desses dados com os dados do IES."
      ],
      "metadata": {
        "id": "AQDOtBfzfYp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte identifica colunas adicionais do `df_surveyDataFrame`. Ela utiliza compreensões de lista para encontrar nomes de colunas que começam com` \"('P2_l_\"e \"('P2_o_\"`. Essas provavelmente representam motivos de insatisfação ou critérios para a escolha de uma empresa, que são consideradas colunas \"dinâmicas\". As colunas identificadas são então adicionadas à `fixed_columnslista` para criar uma `selected_columnslista` final."
      ],
      "metadata": {
        "id": "QOkZQ1RDfPRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de selecionar as colunas, este código verifica se todos os nomes de colunas` selected_columnsrealmente` existem no` df_surveyDataFrame` original. Esta é uma boa prática para evitar erros caso o nome de uma coluna esteja incorreto ou ausente. Em seguida, ele cria um novo DataFrame chamado , df_selectedque contém apenas o selected_columnsfrom verificado `df_survey`. O .`copy()`é usado para garantir que quaisquer modificações` df_selectednão afetem o df_survey.`"
      ],
      "metadata": {
        "id": "FqRK9hnRf3ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta seção se concentra na preparação da \"variável alvo\", que é a coluna que indica a satisfação com a empresa atual (` '('P2_k ', 'Você está satisfeito na sua empresa atual?')'`).\n",
        "\n",
        "\n",
        "* A coluna é selecionada e seu nome é armazenado em `target_col`.\n",
        "* `df_selected.loc[:, target_col] = df_selected[target_col].astype(str) `converte os dados da coluna de destino para o tipo de dados string. Isso garante um tratamento consistente, independentemente do tipo de dado original.\n",
        "*` df_cleaned_survey `= df_selected.dropna(subset=[target_col])remove todas as linhas df_selectedonde o valor target_colestá faltando (NaN).\n",
        "*` df_cleaned_survey = df_cleaned_survey`[df_cleaned_survey[target_col] != 'Desconhecido']filtra ainda mais o DataFrame, removendo linhas cujo valor da coluna de destino é \"Desconhecido\". Isso resulta em um DataFrame df_cleaned_surveyque contém apenas linhas com valores de satisfação válidos e não ausentes."
      ],
      "metadata": {
        "id": "Gak6Vku6gWNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este loop itera por todas as colunas no df_cleaned_surveyDataFrame.\n",
        "\n",
        "Se o nome de uma coluna começar com \"('P2_l_\"ou \"('P2_o_\", os valores ausentes ( NaN) nessa coluna serão preenchidos com o número 0. Isso sugere que essas colunas podem representar contagens ou indicadores em que um valor ausente implica uma contagem zero.\n",
        "Para todas as outras colunas, os valores ausentes são preenchidos com a string 'Desconhecido'. Esta é uma maneira de lidar com dados categóricos ausentes ou outros dados não numéricos. Por fim, uma mensagem é impressa indicando a conclusão do processo de limpeza e seleção dos dados da pesquisa.\n",
        "\n",
        "# Etapa extra: limpeza de nomes de colunas"
      ],
      "metadata": {
        "id": "X6aqyWz2hHVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta seção define uma função clean_col_codeque usa expressões regulares ( re) para extrair a parte do código dos nomes das colunas (a parte entre aspas simples, por exemplo, 'P1_a '). Em seguida, ela aplica essa função a todos os nomes de colunas no df_cleaned_surveyDataFrame, substituindo os nomes originais, mais descritivos, apenas pelos códigos. Isso provavelmente é feito para simplificar os nomes das colunas e facilitar a manipulação e a mesclagem."
      ],
      "metadata": {
        "id": "8wivDTLIhUBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após limpar os nomes das colunas para apenas os códigos, esta parte cria um dicionário survey_rename_mappara mapear esses códigos para nomes mais descritivos e legíveis em inglês. Em seguida, usa o .rename()método para renomear as colunas df_cleaned_surveyde acordo com esse mapeamento.\n",
        "\n",
        "# Parte 2: Agregação de dados do IES por estado (UF)"
      ],
      "metadata": {
        "id": "E83oTmXdhcJZ"
      }
    },
    {
      "source": [
        "\n",
        "# --- Parte 2: Agregação dos Dados das IES por Estado (UF) ---\n",
        "print(\"\\nIniciando Parte 2: Agregação dos dados das IES...\")\n",
        "try:\n",
        "    df_ies = pd.read_csv('MICRODADOS_ED_SUP_IES_2023.CSV', delimiter=';', encoding='latin1')\n",
        "except FileNotFoundError:\n",
        "    print(\"Arquivo 'MICRODADOS_ED_SUP_IES_2023.CSV' não encontrado. Pulando esta etapa.\")\n",
        "    df_ies_aggregated = pd.DataFrame(columns=['uf_ies', 'Total_Tecnicos_Estado', 'Total_Docentes_Estado', 'Total_IES_no_Estado']).set_index('uf_ies')\n",
        "except Exception as e:\n",
        "    print(f\"Um erro ocorreu ao ler o arquivo IES: {e}\")\n",
        "    df_ies_aggregated = pd.DataFrame(columns=['uf_ies', 'Total_Tecnicos_Estado', 'Total_Docentes_Estado', 'Total_IES_no_Estado']).set_index('uf_ies')\n",
        "else:\n",
        "    ies_columns_map = { 'SG_UF_IES': 'uf_ies', 'QT_TEC_TOTAL': 'Qtd_Tecnicos_IES', 'QT_DOC_TOTAL': 'Qtd_Docentes_IES' }\n",
        "    df_ies_selected = df_ies[list(ies_columns_map.keys())].rename(columns=ies_columns_map)\n",
        "\n",
        "    numeric_cols = ['Qtd_Tecnicos_IES', 'Qtd_Docentes_IES']\n",
        "    for col in numeric_cols:\n",
        "        df_ies_selected[col] = pd.to_numeric(df_ies_selected[col], errors='coerce')\n",
        "\n",
        "    df_ies_aggregated = df_ies_selected.groupby('uf_ies').agg({\n",
        "        'Qtd_Tecnicos_IES': 'sum',\n",
        "        'Qtd_Docentes_IES': 'sum',\n",
        "        'uf_ies': 'count'\n",
        "    }).rename(columns={'uf_ies': 'Total_IES_no_Estado', 'Qtd_Tecnicos_IES': 'Total_Tecnicos_Estado', 'Qtd_Docentes_IES': 'Total_Docentes_Estado'})\n",
        "    print(\"Dados das IES agregados com sucesso.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOoS2jwSheYa",
        "outputId": "d25e16d6-ca1b-488c-e29a-6d77a01d820c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando Parte 2: Agregação dos dados das IES...\n",
            "Dados das IES agregados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta seção começa imprimindo uma mensagem para a segunda parte do processo. Em seguida, lê outro arquivo CSV chamado 'MICRODADOS_ED_SUP_IES_2023.CSV'. Este arquivo é lido com um ponto e vírgula ( ;) como delimitador e 'latin1'como codificação, conforme especificado pelos argumentos de pd.read_csv(). Os dados são carregados em um DataFrame chamado df_ies."
      ],
      "metadata": {
        "id": "mC1rhST4hjnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um dicionário ies_columns_mapé criado para mapear os nomes das colunas originais do conjunto de dados IES ( 'SG_UF_IES', 'QT_TEC_TOTAL', 'QT_DOC_TOTAL') para nomes mais descritivos ( 'uf_ies', 'Qtd_Tecnicos_IES', 'Qtd_Docentes_IES'). Em seguida, ele seleciona essas colunas do df_iesDataFrame e as renomeia usando o mapa fornecido, armazenando o resultado em df_ies_selected."
      ],
      "metadata": {
        "id": "ez2rMtklhjU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este loop itera pelo valor especificado numeric_cols. Para cada coluna, ele tenta converter os dados para um tipo numérico usando pd.to_numeric(). O errors='coerce'argumento significa que, se algum valor não puder ser convertido em um número, ele será substituído por NaN(Não é um número).\n",
        "\n"
      ],
      "metadata": {
        "id": "ctogZO5GhjEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é uma etapa fundamental em que os dados do IES são agregados por estado ( 'uf_ies').\n",
        "\n",
        "df_ies_selected.groupby('uf_ies')agrupa o DataFrame pelos valores na 'uf_ies'coluna.\n",
        ".agg({...})então aplica funções de agregação aos dados agrupados:\n",
        "Ele calcula o sumde 'Qtd_Tecnicos_IES'para cada estado.\n",
        "Ele calcula o sumde 'Qtd_Docentes_IES'para cada estado.\n",
        "Ele usa 'count'a 'uf_ies'coluna para contar o número de entradas IES dentro de cada estado.\n",
        ".rename(...)renomeia as colunas agregadas resultantes para que sejam mais descritivas: 'uf_ies'torna-se 'Total_IES_no_Estado', 'Qtd_Tecnicos_IES'torna-se 'Total_Tecnicos_Estado'e 'Qtd_Docentes_Estado'torna-se 'Total_Docentes_Estado'. Os dados agregados são armazenados em df_ies_aggregated. Uma mensagem de sucesso é impressa.\n",
        "\n",
        "# Parte 3: União final do banco de dados (mesclagem)"
      ],
      "metadata": {
        "id": "xpCsl3A0hiUV"
      }
    },
    {
      "source": [
        "# --- Parte 3: União (Merge) Final das Bases de Dados ---\n",
        "print(\"\\nIniciando Parte 3: União final dos dados...\")\n",
        "# O nome da coluna 'uf onde mora' agora é 'uf_onde_mora'\n",
        "df_final = pd.merge(\n",
        "    df_cleaned_survey,\n",
        "    df_ies_aggregated,\n",
        "    left_on='uf_onde_mora',\n",
        "    right_on='uf_ies',\n",
        "    how='left'\n",
        ")\n",
        "print(\"União finalizada.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR98UrZdhf3S",
        "outputId": "30098254-7d0f-4a7f-a2a7-f4a9d8090132"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando Parte 3: União final dos dados...\n",
            "União finalizada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte combina os dados limpos da pesquisa ( df_cleaned_survey) com os dados agregados do IES ( df_ies_aggregated).\n",
        "\n",
        "pd.merge()é usado para executar a operação de junção.\n",
        "df_cleaned_surveyé o DataFrame esquerdo.\n",
        "df_ies_aggregatedé o DataFrame correto.\n",
        "left_on='uf_residencia'especifica a coluna a df_cleaned_surveyser usada para mesclagem.\n",
        "right_on='uf_ies'especifica a coluna a df_ies_aggregatedser usada para mesclagem.\n",
        "how='left'indica uma mesclagem à esquerda. Isso significa que todas as linhas do df_cleaned_survey(DataFrame esquerdo) serão incluídas no resultado. Se um estado de df_cleaned_surveynão tiver uma entrada correspondente em df_ies_aggregated, as colunas de df_ies_aggregatedterão valores ausentes (NaN) para essa linha. O resultado da mesclagem é armazenado em df_final, e uma\n",
        "mensagem de conclusão é impressa.\n",
        "\n",
        "# Parte 4: Salvando o Resultado"
      ],
      "metadata": {
        "id": "lIe0QgLshiIp"
      }
    },
    {
      "source": [
        "# --- Parte 4: Salvando o Resultado ---\n",
        "final_filename = 'dados_tratados_combinados.csv'\n",
        "df_final.to_csv(final_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"\\nProcesso concluído! Arquivo '{final_filename}' gerado com sucesso.\")\n",
        "print(\"\\nVisualização de algumas colunas do arquivo final, incluindo nomes ajustados:\")\n",
        "\n",
        "# Filtra para colunas que existem antes de tentar imprimir\n",
        "colunas_para_verificar = [\n",
        "    'idade', 'genero', 'cargo_atual', 'emprego_status', 'uf_onde_mora', 'total_ies_no_estado'\n",
        "]\n",
        "colunas_existentes = [col for col in colunas_para_verificar if col in df_final.columns]\n",
        "print(df_final[colunas_existentes].head())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeHZ4IuhhFA",
        "outputId": "f3e92f74-d2c4-4ea6-aa3a-0402f53cb612"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processo concluído! Arquivo 'dados_tratados_combinados.csv' gerado com sucesso.\n",
            "\n",
            "Visualização de algumas colunas do arquivo final, incluindo nomes ajustados:\n",
            "   idade     genero                        cargo_atual emprego_status  \\\n",
            "0     31  Masculino  Cientista de Dados/Data Scientist      Empregado   \n",
            "1     30  Masculino          Analista de BI/BI Analyst      Empregado   \n",
            "2     37   Feminino     Analista de Dados/Data Analyst      Empregado   \n",
            "3     22  Masculino                       Desconhecido      Empregado   \n",
            "4     34  Masculino     Analista de Dados/Data Analyst      Empregado   \n",
            "\n",
            "  uf_onde_mora  \n",
            "0           MG  \n",
            "1           ES  \n",
            "2           SP  \n",
            "3           SP  \n",
            "4           MG  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta seção final salva o DataFrame mesclado resultante ( df_final) em um arquivo CSV.\n",
        "\n",
        "final_filename = 'dados_finais_combinados.csv'define o nome do arquivo de saída.\n",
        "df_final.to_csv(final_filename, index=False, encoding='utf-8-sig')salva o DataFrame no arquivo CSV especificado.\n",
        "index=Falseimpede a gravação do índice DataFrame como uma coluna no CSV.\n",
        "encoding='utf-8-sig'especifica a codificação de caracteres para o arquivo de saída. Por fim, mensagens de sucesso são impressas, incluindo o nome do arquivo gerado, e as 5 primeiras linhas de colunas específicas do df_finalDataFrame são impressas no console, permitindo uma rápida visualização dos dados combinados."
      ],
      "metadata": {
        "id": "0WYGuSf5hh2b"
      }
    }
  ]
}