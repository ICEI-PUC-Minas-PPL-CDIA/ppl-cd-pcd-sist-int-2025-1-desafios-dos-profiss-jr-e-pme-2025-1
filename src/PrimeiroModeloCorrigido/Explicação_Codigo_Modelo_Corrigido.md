# üß† Explica√ß√£o dos C√≥digos Finais: Modelos de √Årvore de Decis√£o e Random Forest

---

## Sum√°rio:
[1. Modelo de √Årvore de Decis√£o - Satisfa√ß√£o Bin√°ria](#1modelo-arvore)  
[2. Modelo Random Forest - N√≠vel de IA](#2modelo-random-forest)  

---

<div id='1modelo-arvore'/> 

# 1. Modelo de √Årvore de Decis√£o - Satisfa√ß√£o Bin√°ria

[Arquivo Python](/src/PrimeiroModeloCorrigido/Pergunta1.ipynb)

---

## üìä An√°lise de Satisfa√ß√£o com Dados de Ensino Superior e Mercado de Dados

Este pipeline utiliza uma **√Årvore de Decis√£o** para prever a satisfa√ß√£o bin√°ria (`satisfacao_binaria`) de profissionais da √°rea de dados, com base em vari√°veis como sal√°rio, experi√™ncia, percentual de doutores, modelo de trabalho e n√≠vel de cargo. Inclui an√°lise de texto para motivos de insatisfa√ß√£o e visualiza√ß√µes adicionais para explorar o modelo.

---

## üì¶ Importa√ß√µes de Bibliotecas

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import graphviz
from sklearn.tree import export_graphviz
```

### Descri√ß√£o
- Bibliotecas como `pandas`, `numpy`, `matplotlib` e `seaborn` s√£o usadas para manipula√ß√£o e visualiza√ß√£o de dados.
- `scikit-learn` fornece ferramentas de machine learning e avalia√ß√£o de modelos.
- `nltk` e `TfidfVectorizer` s√£o usados para processamento de linguagem natural.
- `WordCloud` cria nuvens de palavras com termos relevantes.
- `graphviz` visualiza a estrutura da √°rvore de decis√£o.

---

## üß† Prepara√ß√£o de Recursos Lingu√≠sticos

```python
nltk.download('stopwords')
stop_words = stopwords.words('portuguese')
```

- Baixa e define a lista de **palavras irrelevantes (stopwords)** em portugu√™s para ignorar na an√°lise de texto.

---

## üì• Carregamento de Dados

```python
dados = pd.read_csv('dados_processados.csv')
ensino = pd.read_excel('Analise_Ensino_Superior_Consolidada.xlsx')
```

- Carrega dois conjuntos de dados:
  - `dados_processados.csv`: Dados de profissionais (sal√°rio, experi√™ncia, etc.).
  - `Analise_Ensino_Superior_Consolidada.xlsx`: Informa√ß√µes sobre institui√ß√µes de ensino superior (doutores por IES).

---

## üîç Verificar Colunas

```python
print("Colunas dispon√≠veis em ensino:", ensino.columns.tolist())
```

- Mostra as colunas do DataFrame `ensino` para inspe√ß√£o.

---

## üßπ Pr√©-processamento e Enriquecimento de Dados

```python
if '%_Doutores' not in ensino.columns:
    ensino['pct_doutores'] = (ensino['QT_DOC_EX_DOUT'] / ensino['QT_DOC_TOTAL'] * 100).fillna(0)
else:
    ensino['pct_doutores'] = ensino['%_Doutores']
estado_doutores = ensino.groupby('SG_UF_IES')['pct_doutores'].mean().reset_index()
dados = dados.merge(estado_doutores, left_on='estado', right_on='SG_UF_IES', how='left')
```

- Calcula a **porcentagem de doutores** por IES, se n√£o existir, e agrega por estado.
- Faz o **merge** com `dados` para adicionar `pct_doutores` por estado.

```python
dados['salario_medio'].fillna(dados['salario_medio'].median(), inplace=True)
dados['exp_dados_num'].fillna(0, inplace=True)
dados['motivo_insatisfacao'].fillna('', inplace=True)
dados['pct_doutores'].fillna(dados['pct_doutores'].median(), inplace=True)
```

- Substitui valores ausentes com **mediana** (para num√©ricos), **zero** (experi√™ncia) ou **string vazia** (texto).

---

## üéØ Sele√ß√£o e Prepara√ß√£o de Vari√°veis

```python
features = ['salario_medio', 'exp_dados_num', 'pct_doutores', 'modelo_trabalho', 'nivel_cargo']
X = dados[features]
y = dados['satisfacao_binaria']
X = pd.get_dummies(X, columns=['modelo_trabalho', 'nivel_cargo'], drop_first=True)
scaler = StandardScaler()
X[['salario_medio', 'exp_dados_num', 'pct_doutores']] = scaler.fit_transform(X[['salario_medio', 'exp_dados_num', 'pct_doutores']])
```

- Define os **features (X)** e o **alvo (y)** para modelagem.
- Transforma vari√°veis categ√≥ricas (`modelo_trabalho`, `nivel_cargo`) em **vari√°veis dummies**.
- Normaliza vari√°veis num√©ricas com `StandardScaler`.

---

## üß™ Divis√£o de Dados

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
```

- Divide os dados em **80% treino** e **20% teste**, mantendo a propor√ß√£o de classes com `stratify`.

---

## üå≥ Treinamento de Modelo

```python
clf = DecisionTreeClassifier(max_depth=5, min_samples_split=5, criterion='gini', random_state=42)
clf.fit(X_train, y_train)
```

- Treina uma **√Årvore de Decis√£o** com profundidade m√°xima 5, m√≠nimo de 5 amostras por split e crit√©rio Gini.

---

## üìà Avalia√ß√£o do Modelo

```python
y_pred = clf.predict(X_test)
print("\nRelat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred))
scores = cross_val_score(clf, X, y, cv=5)
print("Acur√°cia m√©dia (valida√ß√£o cruzada):", scores.mean())
```

- Gera um **relat√≥rio de classifica√ß√£o** com precis√£o, recall e F1-score.
- Realiza **valida√ß√£o cruzada** (5 folds) para calcular a acur√°cia m√©dia.

---

## üîç Visualiza√ß√µes e An√°lises

### Visualiza√ß√£o da √Årvore

```python
dot_data = export_graphviz(clf, out_file=None, feature_names=X.columns, 
                           class_names=['Insatisfeito', 'Satisfeito'], filled=True, rounded=True)
graph = graphviz.Source(dot_data)
graph.render("arvore_decisao_satisfacao", format="png", view=False)
```

- Gera uma imagem PNG (`arvore_decisao_satisfacao.png`) da estrutura da √°rvore.

### Heatmap de Correla√ß√£o

```python
plt.figure(figsize=(8, 6))
sns.heatmap(X[['salario_medio', 'exp_dados_num', 'pct_doutores']].corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correla√ß√£o entre Features Num√©ricas')
plt.savefig('heatmap_correlacao.png')
plt.show()
```

- Plota a **correla√ß√£o** entre vari√°veis num√©ricas, salva como `heatmap_correlacao.png`.

### Curva de Aprendizado

```python
train_sizes, train_scores, test_scores = learning_curve(clf, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10))
plt.figure(figsize=(8, 6))
plt.plot(train_sizes, train_scores.mean(axis=1), label='Acur√°cia Treino')
plt.plot(train_sizes, test_scores.mean(axis=1), label='Acur√°cia Teste')
plt.xlabel('Tamanho do Conjunto de Treino')
plt.ylabel('Acur√°cia')
plt.title('Curva de Aprendizado da √Årvore de Decis√£o')
plt.legend()
plt.savefig('curva_aprendizado.png')
plt.show()
```

- Mostra a varia√ß√£o da acur√°cia com o tamanho do conjunto de treino, salva como `curva_aprendizado.png`.

### Import√¢ncia das Features

```python
importances = pd.Series(clf.feature_importances_, index=X.columns)
importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))
plt.title('Import√¢ncia das Features para Satisfa√ß√£o')
plt.savefig('importancia_features.png')
plt.show()
```

- Visualiza a **import√¢ncia das vari√°veis** no modelo, salva como `importancia_features.png`.

### Matriz de Confus√£o

```python
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Insatisfeito', 'Satisfeito'], 
            yticklabels=['Insatisfeito', 'Satisfeito'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o')
plt.savefig('matriz_confusao.png')
plt.show()
```

- Mostra previs√µes corretas e incorretas, salva como `matriz_confusao.png`.

### Matriz de Probabilidades

```python
probs = clf.predict_proba(X_test)
matriz_probs = pd.DataFrame(probs, columns=['Prob_Insatisfeito', 'Prob_Satisfeito'])
matriz_probs['Real'] = y_test.values
matriz_probs['Previsto'] = y_pred
print("\nMatriz de Probabilidades (primeiras 10 linhas):")
print(matriz_probs.head(10))
matriz_probs.to_csv('matriz_probabilidades.csv', index=False)
```

- Gera uma tabela com **probabilidades previstas**, valores reais e previstos, salva como `matriz_probabilidades.csv`.

### An√°lise de Texto: Motivos de Insatisfa√ß√£o

```python
tfidf = TfidfVectorizer(max_features=100, stop_words=stop_words)
tfidf_matrix = tfidf.fit_transform(dados['motivo_insatisfacao'])
terms = tfidf.get_feature_names_out()
word_scores = tfidf_matrix.sum(axis=0).A1
word_importance = pd.Series(word_scores, index=terms).sort_values(ascending=False)
```

- Aplica **TF-IDF** para extrair termos relevantes de `motivo_insatisfacao`.

### Nuvem de Palavras

```python
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_importance)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Nuvem de Palavras - Motivos de Insatisfa√ß√£o')
plt.savefig('wordcloud_insatisfacao.png')
plt.show()
```

- Gera e salva uma **nuvem de palavras** com os principais motivos de insatisfa√ß√£o.

---

<div id='2modelo-random-forest'/> 

# 2. Modelo Random Forest - N√≠vel de IA

[Arquivo Python](/src/PrimeiroModeloCorrigido/Pergunta2.ipynb)

---

## ü§ñ Classifica√ß√£o do N√≠vel de Acesso √† IA com Random Forest

Este pipeline realiza a classifica√ß√£o do n√≠vel de envolvimento com IA (`nivel_ia_encoded`) com base em habilidades t√©cnicas (`sql`, `python`, `powerbi`, `aws`), n√≠vel de ensino e quantidade de doutores, utilizando um **Random Forest Classifier**.

---

## üì¶ Importa√ß√µes

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import graphviz
from sklearn.tree import export_graphviz
```

- Importa bibliotecas para manipula√ß√£o de dados, modelagem, avalia√ß√£o e visualiza√ß√£o.

---

## üì• Carregamento de Dados

```python
dados = pd.read_csv('dados_processados.csv')
ensino = pd.read_excel('Analise_Ensino_Superior_Consolidada.xlsx')
```

- Carrega os dados principais (`dados_processados.csv`) e os dados de ensino superior (`Analise_Ensino_Superior_Consolidada.xlsx`).

---

## üß¨ Enriquecimento dos Dados

```python
estado_doutores = ensino.groupby('SG_UF_IES')['QT_DOC_EX_DOUT'].mean().reset_index()
dados = dados.merge(estado_doutores, left_on='estado', right_on='SG_UF_IES', how='left')
```

- Adiciona a **m√©dia de doutores por estado** ao DataFrame principal.

---

## üßπ Pr√©-processamento

```python
dados['nivel_ia'] = dados['nivel_ia'].fillna('Outros')
dados['QT_DOC_EX_DOUT'] = dados['QT_DOC_EX_DOUT'].fillna(dados['QT_DOC_EX_DOUT'].median())
le = LabelEncoder()
dados['nivel_ia_encoded'] = le.fit_transform(dados['nivel_ia'])
class_counts = dados['nivel_ia_encoded'].value_counts()
valid_classes = class_counts[class_counts >= 2].index
dados = dados[dados['nivel_ia_encoded'].isin(valid_classes)]
```

- Preenche valores ausentes com **"Outros"** (n√≠vel de IA) ou **mediana** (doutores).
- Codifica `nivel_ia` com **LabelEncoder**.
- Filtra classes com menos de 2 amostras para evitar erros no treinamento.

---

## üß† Sele√ß√£o de Features

```python
habilidades = ['sql', 'python', 'powerbi', 'aws', 'nivel_ensino', 'QT_DOC_EX_DOUT']
X = dados[habilidades]
y = dados['nivel_ia_encoded']
X = pd.get_dummies(X, columns=['nivel_ensino'], drop_first=True)
```

- Define os **features (X)** e o **alvo (y)** para prever o n√≠vel de envolvimento com IA.
- Aplica **one-hot encoding** em `nivel_ensino`.

---

## üìä Divis√£o dos Dados

```python
try:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
except ValueError:
    print("Stratifica√ß√£o falhou. Usando divis√£o sem estratifica√ß√£o.")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

- Divide em **80% treino** e **20% teste**, com tentativa de estratifica√ß√£o. Se falhar, usa divis√£o simples.

---

## üå≥ Treinamento com Random Forest

```python
rf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, random_state=42)
rf.fit(X_train, y_train)
```

- Treina um **Random Forest** com 100 √°rvores, profundidade m√°xima 10 e m√≠nimo de 5 amostras por split.

---

## üìà Avalia√ß√£o do Modelo

```python
y_pred = rf.predict(X_test)
print("\nRelat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred, target_names=le.classes_[valid_classes]))
scores = cross_val_score(rf, X, y, cv=5)
print("Acur√°cia m√©dia (valida√ß√£o cruzada):", scores.mean())
```

- Gera **m√©tricas de desempenho** (precis√£o, recall, F1-score) por classe.
- Calcula **acur√°cia m√©dia** com valida√ß√£o cruzada (5 folds).

---

## üîç Visualiza√ß√µes e An√°lises

### Visualiza√ß√£o de uma √Årvore

```python
tree = rf.estimators_[0]
dot_data = export_graphviz(tree, out_file=None, feature_names=X.columns, 
                           class_names=[str(cls) for cls in le.classes_[valid_classes]], 
                           filled=True, rounded=True)
graph = graphviz.Source(dot_data)
graph.render("arvore_random_forest", format="png", view=False)
```

- Plota uma √∫nica √°rvore do Random Forest, salva como `arvore_random_forest.png`.

### Curva de Aprendizado

```python
train_sizes, train_scores, test_scores = learning_curve(rf, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10))
plt.figure(figsize=(8, 6))
plt.plot(train_sizes, train_scores.mean(axis=1), label='Acur√°cia Treino')
plt.plot(train_sizes, test_scores.mean(axis=1), label='Acur√°cia Teste')
plt.xlabel('Tamanho do Conjunto de Treino')
plt.ylabel('Acur√°cia')
plt.title('Curva de Aprendizado da Random Forest')
plt.legend()
plt.savefig('curva_aprendizado_rf.png')
plt.show()
```

- Mostra a **acur√°cia** em fun√ß√£o do tamanho do conjunto de treino, salva como `curva_aprendizado_rf.png`.

### Import√¢ncia das Features

```python
importances = pd.Series(rf.feature_importances_, index=X.columns)
importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))
plt.title('Import√¢ncia das Habilidades para IA Generativa')
plt.savefig('importancia_features_rf.png')
plt.show()
```

- Visualiza a **import√¢ncia de cada feature**, salva como `importancia_features_rf.png`.

### An√°lise de Correla√ß√£o

```python
corr_data = X.copy()
corr_data['nivel_ia_encoded'] = y
correlacoes = corr_data.corr(method='spearman')
plt.figure(figsize=(8, 6))
sns.heatmap(correlacoes, annot=True, cmap='coolwarm', center=0)
plt.title('Correla√ß√£o entre Habilidades e N√≠vel de IA')
plt.savefig('heatmap_correlacao_rf.png')
plt.show()
```

- Gera um **heatmap** com correla√ß√µes de Spearman, salva como `heatmap_correlacao_rf.png`.

### Matriz de Confus√£o

```python
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=le.classes_[valid_classes], yticklabels=le.classes_[valid_classes])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o - Random Forest')
plt.savefig('matriz_confusao_rf.png')
plt.show()
```

- Visualiza previs√µes corretas e incorretas, salva como `matriz_confusao_rf.png`.

### Matriz de Probabilidades

```python
probs = rf.predict_proba(X_test)
matriz_probs = pd.DataFrame(probs, columns=[f'Prob_{cls}' for cls in le.classes_[valid_classes]])
matriz_probs['Real'] = [le.classes_[i] for i in y_test]
matriz_probs['Previsto'] = [le.classes_[i] for i in y_pred]
print("\nMatriz de Probabilidades (primeiras 10 linhas):")
print(matriz_probs.head(10))
matriz_probs.to_csv('matriz_probabilidades_rf.csv', index=False)
```

- Gera uma tabela com **probabilidades previstas**, valores reais e previstos, salva como `matriz_probabilidades_rf.csv`.

---

## üîç Notas Adicionais
- **Modelo de √Årvore**: Focado em satisfa√ß√£o bin√°ria, com an√°lise de texto para motivos de insatisfa√ß√£o. Ideal para interpretabilidade.
- **Modelo Random Forest**: Focado em n√≠vel de IA (multiclasse), com √™nfase em habilidades t√©cnicas. Mais robusto, mas menos interpret√°vel diretamente.
- **Gr√°ficos adicionais**: Curvas de aprendizado e matrizes de confus√£o ajudam a avaliar a generaliza√ß√£o e erros dos modelos.
- **Matrizes de solu√ß√£o**: Fornecem insights detalhados sobre previs√µes e incertezas.
- **Depend√™ncias**: Instale `graphviz` no sistema e bibliotecas Python (`pip install pandas numpy scikit-learn matplotlib seaborn nltk wordcloud graphviz`).

---
