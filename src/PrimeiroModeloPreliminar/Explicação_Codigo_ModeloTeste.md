# üß† Explica√ß√£o Codigo Modelo1 Teste
---
## Sumario:
[1. Pergunta](#1pergunta)  

[2. Pergunta](#2pergunta)  

---
<div id='1pergunta'/> 
  
# 1.Pergunta:
[Codigo em Python](/src/PrimeiroModeloPreliminar/Pergunta1.ipynb)

# üìä An√°lise de Satisfa√ß√£o com Dados de Ensino Superior e Mercado de Dados

## üì¶ Importa√ß√µes de Bibliotecas

```python
import pandas as pd 
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
```

### Descri√ß√£o
- Bibliotecas como `pandas`, `numpy`, `matplotlib` e `seaborn` s√£o usadas para manipula√ß√£o e visualiza√ß√£o de dados.
- `scikit-learn` fornece ferramentas de machine learning e avalia√ß√£o de modelos.
- `nltk` √© usado para processamento de linguagem natural.
- `WordCloud` √© usada para criar nuvens de palavras com termos importantes.

---

## üß† Prepara√ß√£o de Recursos Lingu√≠sticos

```python
nltk.download('stopwords')
stop_words = stopwords.words('portuguese')
```

- Baixa e define a lista de **palavras irrelevantes (stopwords)** em portugu√™s para ignorar na an√°lise de texto.

---

## üì• Carregamento de Dados

```python
dados = pd.read_csv('dados_processados.csv')
ensino = pd.read_excel('Analise_Ensino_Superior_Consolidada.xlsx')
```

- Carrega dois conjuntos de dados:
  - `dados_processados.csv`: dados de profissionais da √°rea de dados.
  - `Analise_Ensino_Superior_Consolidada.xlsx`: informa√ß√µes sobre institui√ß√µes de ensino superior.

---

## üîç Verificar colunas

```python
print("Colunas dispon√≠veis em ensino:", ensino.columns.tolist())
```

- Mostra as colunas do DataFrame `ensino` para inspe√ß√£o.

---

## üßπ Pr√©-processamento e Enriquecimento de Dados

```python
# Calcula a porcentagem de doutores por estado
if '%_Doutores' not in ensino.columns:
    ensino['pct_doutores'] = (ensino['QT_DOC_EX_DOUT'] / ensino['QT_DOC_TOTAL'] * 100).fillna(0)
else:
    ensino['pct_doutores'] = ensino['%_Doutores']
```

- Calcula a porcentagem de doutores nas IES (caso a coluna n√£o exista).

```python
estado_doutores = ensino.groupby('SG_UF_IES')['pct_doutores'].mean().reset_index()
dados = dados.merge(estado_doutores, left_on='estado', right_on='SG_UF_IES', how='left')
```

- Adiciona a m√©dia de doutores por estado ao DataFrame `dados`.

```python
# Tratamento de valores ausentes
dados['salario_medio'].fillna(dados['salario_medio'].median(), inplace=True)
dados['exp_dados_num'].fillna(0, inplace=True)
dados['motivo_insatisfacao'].fillna('', inplace=True)
dados['pct_doutores'].fillna(dados['pct_doutores'].median(), inplace=True)
```

- Substitui valores ausentes com valores apropriados (mediana, zero ou string vazia).

---

## üéØ Sele√ß√£o e Prepara√ß√£o de Vari√°veis

```python
features = ['salario_medio', 'exp_dados_num', 'pct_doutores', 'modelo_trabalho', 'nivel_cargo']
X = dados[features]
y = dados['satisfacao_binaria']
```

- Define os **features (X)** e o **alvo (y)** para modelagem.

```python
X = pd.get_dummies(X, columns=['modelo_trabalho', 'nivel_cargo'], drop_first=True)
```

- Transforma vari√°veis categ√≥ricas em **vari√°veis dummies (one-hot encoding)**.

```python
scaler = StandardScaler()
X[['salario_medio', 'exp_dados_num', 'pct_doutores']] = scaler.fit_transform(X[['salario_medio', 'exp_dados_num', 'pct_doutores']])
```

- Normaliza as vari√°veis num√©ricas.

---

## üß™ Divis√£o de Dados

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
```

- Divide os dados em treino e teste (80/20), mantendo a propor√ß√£o de classes.

---

## üå≥ Treinamento de Modelo

```python
clf = DecisionTreeClassifier(max_depth=5, min_samples_split=5, criterion='gini', random_state=42)
clf.fit(X_train, y_train)
```

- Treina uma √°rvore de decis√£o com profundidade e crit√©rios definidos.

---

## üìà Avalia√ß√£o do Modelo

```python
y_pred = clf.predict(X_test)
print("Relat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred))
```

- Gera um relat√≥rio de desempenho (precis√£o, recall, F1-score).

```python
scores = cross_val_score(clf, X, y, cv=5)
print("Acur√°cia m√©dia (valida√ß√£o cruzada):", scores.mean())
```

- Realiza **valida√ß√£o cruzada** (5 folds) e mostra a acur√°cia m√©dia.

---

## üîç Import√¢ncia das Features

```python
importances = pd.Series(clf.feature_importances_, index=X.columns)
importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))
plt.title('Import√¢ncia das Features para Satisfa√ß√£o')
plt.show()
```

- Visualiza a **import√¢ncia das vari√°veis** no modelo de decis√£o.

---

## üìù An√°lise de Texto: Motivos de Insatisfa√ß√£o

```python
tfidf = TfidfVectorizer(max_features=100, stop_words=stop_words)
tfidf_matrix = tfidf.fit_transform(dados['motivo_insatisfacao'])
```

- Aplica **TF-IDF** para extrair os termos mais relevantes dos textos.

```python
terms = tfidf.get_feature_names_out()
word_scores = tfidf_matrix.sum(axis=0).A1
word_importance = pd.Series(word_scores, index=terms).sort_values(ascending=False)
```

- Calcula a import√¢ncia dos termos.

---

## ‚òÅÔ∏è Nuvem de Palavras

```python
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_importance)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Nuvem de Palavras - Motivos de Insatisfa√ß√£o')
plt.savefig('wordcloud_insatisfacao.png')
```

- Gera e salva uma **nuvem de palavras** com os principais motivos de insatisfa√ß√£o.

---


<div id='2pergunta'/> 


  
# 2. Pergunta:
[Codigo em Python](/src/PrimeiroModeloPreliminar/Pergunta_2.ipynb)

---

# ü§ñ Classifica√ß√£o do N√≠vel de Acesso √† IA com Random Forest

Este pipeline realiza a classifica√ß√£o do n√≠vel de envolvimento com IA usando algoritmos de aprendizado supervisionado, com foco em habilidades t√©cnicas e dados de ensino superior.

---

## üì¶ Importa√ß√µes

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns
```

- Importa bibliotecas para manipula√ß√£o de dados, modelagem, avalia√ß√£o e visualiza√ß√£o.

---

## üì• Carregamento de Dados

```python
dados = pd.read_csv('dados_processados.csv')
ensino = pd.read_excel('Analise_Ensino_Superior_Consolidada.xlsx')
```

- Carrega os dados principais (`dados_processados.csv`) e os dados de ensino superior (`Analise_Ensino_Superior_Consolidada.xlsx`).

---

## üß¨ Enriquecimento dos Dados

```python
estado_doutores = ensino.groupby('SG_UF_IES')['QT_DOC_EX_DOUT'].mean().reset_index()
dados = dados.merge(estado_doutores, left_on='estado', right_on='SG_UF_IES', how='left')
```

- Adiciona ao dataset principal a m√©dia de doutores por estado, cruzando com o c√≥digo da unidade federativa (`SG_UF_IES`).

---

## üßπ Pr√©-processamento

```python
dados['nivel_ia'] = dados['nivel_ia'].fillna('Outros')
dados['QT_DOC_EX_DOUT'] = dados['QT_DOC_EX_DOUT'].fillna(dados['QT_DOC_EX_DOUT'].median())
```

- Preenche valores ausentes com estrat√©gias adequadas (ex: "Outros", mediana).

---

## üè∑Ô∏è Codifica√ß√£o das Classes

```python
le = LabelEncoder()
dados['nivel_ia_encoded'] = le.fit_transform(dados['nivel_ia'])
```

- Transforma a vari√°vel `nivel_ia` (categ√≥rica) em valores num√©ricos codificados.

```python
# Filtrar classes com menos de 2 amostras
valid_classes = class_counts[class_counts >= 2].index
dados = dados[dados['nivel_ia_encoded'].isin(valid_classes)]
```

- Remove classes muito pequenas (com menos de 2 amostras) para evitar problemas de treino.

---

## üß† Sele√ß√£o de Features

```python
habilidades = ['sql', 'python', 'powerbi', 'aws', 'nivel_ensino', 'QT_DOC_EX_DOUT']
X = dados[habilidades]
y = dados['nivel_ia_encoded']
```

- Define os atributos que ser√£o usados para prever o n√≠vel de envolvimento com IA.

```python
X = pd.get_dummies(X, columns=['nivel_ensino'], drop_first=True)
```

- Codifica a vari√°vel `nivel_ensino` com one-hot encoding.

---

## üìä Divis√£o dos Dados

```python
# Tenta usar stratify para manter propor√ß√µes; se falhar, divide sem stratifica√ß√£o
try:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
except ValueError:
    print("Stratifica√ß√£o falhou. Usando divis√£o sem estratifica√ß√£o.")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

---

## üå≥ Treinamento com Random Forest

```python
rf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, random_state=42)
rf.fit(X_train, y_train)
```

- Modelo Random Forest com 100 √°rvores, profundidade m√°xima de 10 e no m√≠nimo 5 amostras para split.

---

## üìà Avalia√ß√£o do Modelo

```python
y_pred = rf.predict(X_test)
print("Relat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred, target_names=le.classes_[valid_classes]))
```

- Mostra m√©tricas de desempenho (precis√£o, recall, F1-score) por classe.

```python
scores = cross_val_score(rf, X, y, cv=5)
print("Acur√°cia m√©dia (valida√ß√£o cruzada):", scores.mean())
```

- Valida√ß√£o cruzada para medir robustez do modelo.

---

## üîç Import√¢ncia das Features

```python
importances = pd.Series(rf.feature_importances_, index=X.columns)
importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))
plt.title('Import√¢ncia das Habilidades para IA Generativa')
plt.show()
```

- Visualiza a influ√™ncia de cada vari√°vel no modelo.

---

## üî• An√°lise de Correla√ß√£o

```python
corr_data = X.copy()
corr_data['nivel_ia_encoded'] = y
correlacoes = corr_data.corr(method='spearman')
sns.heatmap(correlacoes, annot=True, cmap='coolwarm', center=0)
plt.title('Correla√ß√£o entre Habilidades e N√≠vel de IA')
plt.savefig('heatmap_correlacao.png')
plt.show()
```

- Gera um **heatmap** com correla√ß√µes de Spearman entre as vari√°veis e o n√≠vel de IA.

---
